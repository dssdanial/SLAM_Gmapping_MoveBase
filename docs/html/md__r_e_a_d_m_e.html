<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>SLAM_gmapping_movebase: # RT1 final project: SLAM_gmapping_movebase</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">SLAM_gmapping_movebase
   &#160;<span id="projectnumber">1</span>
   </div>
   <div id="projectbrief">A software architecture for the control of the robot in the environment.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title"># RT1 final project: SLAM_gmapping_movebase </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>A software architecture for the control of the robot in the environment. The software relys on the move_base and gmapping packages for localizing the robot and plan the motion.</p>
<p>In this project, the software architecture should be able to get the user request, and let the robot execute one of the following behaviors (depending on the userâ€™s input): </p><pre class="fragment">  1-  autonomously reach a x,y coordinate inserted by the user
  2-  let the user drive the robot with the keyboard
  3-  let the user drive the robot assisting them to avoid collisions
</pre><ul>
<li> align="center"The Robot can be obsereved in both Rviz and Gazebo environments as follows. </li>
</ul>
<p><img src="https://github.com/dssdanial/SLAM_gmapping_movebase/blob/main/images/map_01.png" alt="" width="500" height="300" class="inline"/> </p>
<p align="center"></p>
<p><img src="https://github.com/dssdanial/SLAM_gmapping_movebase/blob/main/images/map_02_rviz.png" alt="" width="500" height="300" class="inline"/> </p>
<p>This represents the point of view from Rviz. Rviz is a 3D visualization tool for ROS applications. It offers a view of the robot model, acquires sensor information from the robot sensors, and reproduces the acquired data. It can display data from video cameras, lasers, 3D and 2D devices, including images and point clouds. To obtain this result the robot must have explored all the surroundings since with the gmapping algorithm we do not have a totale knowledge of the environment, whereas with a pre-existing map we do.</p>
<h1><a class="anchor" id="autotoc_md0"></a>
## How to Install and run</h1>
<p>At first, some packages are required to be installed, if they aren't already installed,it is possible to setup them by the following commands.</p>
<ul>
<li>Install xterm: <div class="fragment"><div class="line">$ sudo apt install xterm</div>
</div><!-- fragment --></li>
<li>Using the SLAM-Gmapping package: <div class="fragment"><div class="line">$ git clone https://github.com/CarmineD8/slam_gmapping.git</div>
</div><!-- fragment --></li>
<li>using the Navigation package: <div class="fragment"><div class="line">$ sudo apt-get install ros-&lt;your_ros_distro&gt;-navigation</div>
</div><!-- fragment --></li>
<li>Install teleop-twist-keyboard package: <div class="fragment"><div class="line">$ sudo apt-get install ros-&lt;your_ros_distro&gt;-teleop-twist-keyboard</div>
</div><!-- fragment --></li>
</ul>
<p>After installing the required packages, it is time to run the simulation. Concequently, a launch file is porvided here as follows. </p><div class="fragment"><div class="line">$ roslaunch RTassignment3 main.launch</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md1"></a>
Introduction</h1>
<ul>
<li>Regarding the first goal, the <code>move_base</code> pakage requires goal to be sent to the topic <code>move_base/goal</code>, by sending a message of type <code>move_base_msgs/MoveBaseActionGoal</code>.</li>
<li>Regarding the goals 2) and 3), it should rely on the <code>teleop_twist_keyboard</code>, however, in case 3), the cmd_vel may need to be corrected when the user is going to crash into obstacles. Carefully consider the architecture of the system.</li>
<li>Concerning the goal 3), the robot should not go forward if there is an obstacle in the front, also should not turn left/right if there are obstacles on the left/right.</li>
</ul>
<h1><a class="anchor" id="autotoc_md2"></a>
Interface Node</h1>
<p>The purpose of this node is showing an interface in which the user can choose different modes, reset the simulation or quit the execution of the program. When an input is given, the node runs the correct command to launch the related node.</p>
<p>The interface is simply designed as a list of commands as follows:</p>
<p><img src="https://github.com/dssdanial/SLAM_gmapping_movebase/blob/main/images/interface.png" alt="" width="500" height="300" class="inline"/> </p>
<h1><a class="anchor" id="autotoc_md3"></a>
(I) Autonomous XY-Position Node</h1>
<p>Once a x-y position receieved by user, this node drives the robot to the desired position in the environment. First of all the node requires from the user the <code>x</code> and <code>y</code> position of the goal, then a message of type <code>move_base_msgs/MoveBaseActionGoal</code> is generated and published in the <code>/move_base/goal</code> topic. Every goal is tracked by the node with its <code>id</code>, that is randomly generated inside the node itself.</p>
<h1><a class="anchor" id="autotoc_md4"></a>
Nodes struscture</h1>
<p><img src="https://github.com/dssdanial/SLAM_gmapping_movebase/blob/main/images/mode01.jpg" alt="" width="600" height="500" class="inline"/> </p>
<p>After establishing the position, the user can at any time cancel the goal (pressing the <code>q</code> key) and quit the execurtion (pressing the <code>s</code> key). If one of the above keys is pressed, a message of type <code>actionlib_msgs/GoalID</code> is generated and then published in the <code>/move_base/cancel</code> topic to cancel the goal.</p>
<h1><a class="anchor" id="autotoc_md5"></a>
video</h1>
<p>The result of the **_first_** task is shown as the following video:</p>
<p><a href="https://user-images.githubusercontent.com/32397445/182872817-f4ccb08b-4d68-4531-80b7-29de31634bc2.mp4">https://user-images.githubusercontent.com/32397445/182872817-f4ccb08b-4d68-4531-80b7-29de31634bc2.mp4</a></p>
<p>In order to check wheather the robot has reached the goal or not, a <code>/move_base/status</code> message handler is implemented. It checks the meassages published on the previously mentioned topic. In particular, when the robot stops, the status code becomes <code>3</code> if the robot has reached the goal position, otherwise the status code becomes <code>4</code> if the robot can not reach the given position.</p>
<h1><a class="anchor" id="autotoc_md6"></a>
(II) Manual Drive- &lt;em&gt;without&lt;/em&gt; Obstacle Avoidance assistant</h1>
<p>This node aims to give the user the possibility of moving the robot in the environment using the keyboard. In order to manage the robot's movement in the environment four parameters are considred, two used for the velocity values (both linear and angular velocity) and two used for the directions. Each specific key modifies the above mentioned variables to drive the robot through the maze. Once the velocity and the direction has been modified new velocities are published in the <code>/cmd_vel</code> topic.</p>
<p>An interface has been considered as a list of the commands to move the robot and increase/decrease velocities as follows:</p>
<p><img src="https://github.com/dssdanial/SLAM_gmapping_movebase/blob/main/images/keyboard.png" alt="" width="500" height="300" class="inline"/> </p>
<h1><a class="anchor" id="autotoc_md7"></a>
Nodes struscture</h1>
<p><img src="https://github.com/dssdanial/SLAM_gmapping_movebase/blob/main/images/mode02.jpg" alt="" width="500" height="300" class="inline"/> </p>
<h1><a class="anchor" id="autotoc_md8"></a>
Video</h1>
<p>The result of the **_second_** task is shown as the following video:</p>
<p><a href="https://user-images.githubusercontent.com/32397445/182872919-e427823f-907b-438d-9582-4881dcccf7d8.mp4">https://user-images.githubusercontent.com/32397445/182872919-e427823f-907b-438d-9582-4881dcccf7d8.mp4</a></p>
<h1><a class="anchor" id="autotoc_md9"></a>
(III) Manual Drive- &lt;em&gt;with&lt;/em&gt; Obstacle Avoidance assistant</h1>
<p>This is the last node developed, basically it aims to give the user the possibility to drive the robot in the environment using the keyboard, but in this case it is also necessary to provide obstacle avoidance autonomously. Since the goal is partially similar to what was done with the previous node, part of the code has been re-used for this node. To manage obstacle avoidance the robot laser scanner is used,and the node subscribes from the <code>/scan</code> topic. This topic provide a <code>ranges array</code> composed of 720 elements. The ranges array is filled with the distance of the obstacles in the <code>180Â°</code> field of view of the robot. It is possible to divide the array in three parts (robot's left right and front) and check the closest obstacle in each section, then if the robot will be close to an obstacle it will be properly rotated.</p>
<h1><a class="anchor" id="autotoc_md10"></a>
Nodes struscture</h1>
<p><img src="https://github.com/dssdanial/SLAM_gmapping_movebase/blob/main/images/mode03.jpg" alt="" width="500" height="300" class="inline"/> </p>
<h1><a class="anchor" id="autotoc_md11"></a>
Video</h1>
<p>The result of the **_third_** task is shown as the following video:</p>
<p><a href="https://user-images.githubusercontent.com/32397445/182872987-ba6ce54d-a143-4cc3-a866-5fc8f35cb515.mp4">https://user-images.githubusercontent.com/32397445/182872987-ba6ce54d-a143-4cc3-a866-5fc8f35cb515.mp4</a></p>
<h1><a class="anchor" id="autotoc_md12"></a>
Pseudo code</h1>
<h1><a class="anchor" id="autotoc_md13"></a>
control of the robot</h1>
<div class="fragment"><div class="line">listen for UI node&#39;s commands</div>
<div class="line"> </div>
<div class="line"> if autonomous drive</div>
<div class="line">   receive coordinates</div>
<div class="line">   start driving action with coordinates</div>
<div class="line"> </div>
<div class="line"> elseif manual drive</div>
<div class="line">   redirect teleop_twist_keyboard node to cmd_vel topic</div>
<div class="line"> </div>
<div class="line"> elseif assisted drive</div>
<div class="line">   run collision avoidance on teleop_twist_keyboard&#39;s commands</div>
<div class="line">   send filtered commands to cmd_vel</div>
<div class="line"> </div>
<div class="line"> send info to Interface node</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md14"></a>
Coclusion and possible improvments</h1>
<p>All proposed algorithms are executed correctly and the robot completed tasks as well. Results are satisfying, however, some improvements can be achieved.</p><ul>
<li>reaching a desired point seems taking some delays, so, this could be modified by tuning parameters.</li>
<li>A queue could be implemented where goals are reached sequentially.</li>
<li>When the map of the environment is completed, the robot is not able to understand the priori points whether it is reachable or not, which could be improved in further developments. </li>
</ul>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.17
</small></address>
</body>
</html>
